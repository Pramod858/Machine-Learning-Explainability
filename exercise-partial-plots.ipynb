{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Machine Learning Explainability](https://www.kaggle.com/learn/machine-learning-explainability) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/partial-plots).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"## Set Up\n\nToday you will create partial dependence plots and practice building insights with data from the [Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction) competition.\n\nWe have again provided code to do the basic loading, review and model-building. Run the cell below to set everything up:","metadata":{}},{"cell_type":"code","source":"# Get most recent checking code\n!pip install git+https://github.com/Kaggle/learntools.git\n!pip install git+https://github.com/SauceCat/PDPbox.git\nfrom learntools.ml_explainability.ex4 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:18:59.879918Z","iopub.execute_input":"2023-02-28T18:18:59.880288Z","iopub.status.idle":"2023-02-28T18:19:42.889513Z","shell.execute_reply.started":"2023-02-28T18:18:59.880253Z","shell.execute_reply":"2023-02-28T18:19:42.887934Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/Kaggle/learntools.git\n  Cloning https://github.com/Kaggle/learntools.git to /tmp/pip-req-build-enkq0eni\n  Running command git clone --filter=blob:none --quiet https://github.com/Kaggle/learntools.git /tmp/pip-req-build-enkq0eni\n  fatal: unable to access 'https://github.com/Kaggle/learntools.git/': Could not resolve host: github.com\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/Kaggle/learntools.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-enkq0eni\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n\n\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/Kaggle/learntools.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-enkq0eni\u001b[0m did not run successfully.\n\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\nCollecting git+https://github.com/SauceCat/PDPbox.git\n  Cloning https://github.com/SauceCat/PDPbox.git to /tmp/pip-req-build-vswvnk66\n  Running command git clone --filter=blob:none --quiet https://github.com/SauceCat/PDPbox.git /tmp/pip-req-build-vswvnk66\n  fatal: unable to access 'https://github.com/SauceCat/PDPbox.git/': Could not resolve host: github.com\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/SauceCat/PDPbox.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-vswvnk66\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n\n\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/SauceCat/PDPbox.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-vswvnk66\u001b[0m did not run successfully.\n\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\nSetup Complete\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Environment Set-Up for feedback system.\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ml_explainability.ex3 import *\nprint(\"Setup Complete\")\n\n# Data manipulation code below here\ndata = pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv', nrows=50000)\n\n# Remove data with extreme outlier coordinates or negative fares\ndata = data.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +\n                  'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +\n                  'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +\n                  'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +\n                  'fare_amount > 0'\n                  )\n\ny = data.fare_amount\n\nbase_features = ['pickup_longitude',\n                 'pickup_latitude',\n                 'dropoff_longitude',\n                 'dropoff_latitude']\n\nX = data[base_features]\n\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nfirst_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y)\nprint(\"Data sample:\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:42.892554Z","iopub.execute_input":"2023-02-28T18:19:42.893156Z","iopub.status.idle":"2023-02-28T18:19:47.638284Z","shell.execute_reply.started":"2023-02-28T18:19:42.893103Z","shell.execute_reply":"2023-02-28T18:19:47.637238Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Setup Complete\nData sample:\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                             key  fare_amount          pickup_datetime  \\\n2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n6    2012-11-20 20:35:00.0000001          7.5  2012-11-20 20:35:00 UTC   \n7   2012-01-04 17:22:00.00000081         16.5  2012-01-04 17:22:00 UTC   \n\n   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n2        -73.982738        40.761270         -73.991242         40.750562   \n3        -73.987130        40.733143         -73.991567         40.758092   \n4        -73.968095        40.768008         -73.956655         40.783762   \n6        -73.980002        40.751662         -73.973802         40.764842   \n7        -73.951300        40.774138         -73.990095         40.751048   \n\n   passenger_count  \n2                2  \n3                1  \n4                1  \n6                1  \n7                1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>fare_amount</th>\n      <th>pickup_datetime</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n      <th>passenger_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>2011-08-18 00:35:00.00000049</td>\n      <td>5.7</td>\n      <td>2011-08-18 00:35:00 UTC</td>\n      <td>-73.982738</td>\n      <td>40.761270</td>\n      <td>-73.991242</td>\n      <td>40.750562</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012-04-21 04:30:42.0000001</td>\n      <td>7.7</td>\n      <td>2012-04-21 04:30:42 UTC</td>\n      <td>-73.987130</td>\n      <td>40.733143</td>\n      <td>-73.991567</td>\n      <td>40.758092</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-03-09 07:51:00.000000135</td>\n      <td>5.3</td>\n      <td>2010-03-09 07:51:00 UTC</td>\n      <td>-73.968095</td>\n      <td>40.768008</td>\n      <td>-73.956655</td>\n      <td>40.783762</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2012-11-20 20:35:00.0000001</td>\n      <td>7.5</td>\n      <td>2012-11-20 20:35:00 UTC</td>\n      <td>-73.980002</td>\n      <td>40.751662</td>\n      <td>-73.973802</td>\n      <td>40.764842</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2012-01-04 17:22:00.00000081</td>\n      <td>16.5</td>\n      <td>2012-01-04 17:22:00 UTC</td>\n      <td>-73.951300</td>\n      <td>40.774138</td>\n      <td>-73.990095</td>\n      <td>40.751048</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.639451Z","iopub.execute_input":"2023-02-28T18:19:47.639708Z","iopub.status.idle":"2023-02-28T18:19:47.681343Z","shell.execute_reply.started":"2023-02-28T18:19:47.639683Z","shell.execute_reply":"2023-02-28T18:19:47.680566Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\ncount  31289.000000      31289.000000     31289.000000       31289.000000   \nmean       8.483093        -73.976860        40.756917         -73.975342   \nstd        4.628164          0.014635         0.018170           0.015917   \nmin        0.010000        -73.999999        40.700013         -73.999999   \n25%        5.500000        -73.988039        40.744947         -73.987125   \n50%        7.500000        -73.979691        40.758027         -73.978547   \n75%       10.100000        -73.967823        40.769580         -73.966435   \nmax      165.000000        -73.900062        40.799952         -73.900062   \n\n       dropoff_latitude  passenger_count  \ncount      31289.000000     31289.000000  \nmean          40.757473         1.656141  \nstd            0.018661         1.284899  \nmin           40.700020         0.000000  \n25%           40.745922         1.000000  \n50%           40.758559         1.000000  \n75%           40.770427         2.000000  \nmax           40.799999         6.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fare_amount</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n      <th>passenger_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>31289.000000</td>\n      <td>31289.000000</td>\n      <td>31289.000000</td>\n      <td>31289.000000</td>\n      <td>31289.000000</td>\n      <td>31289.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8.483093</td>\n      <td>-73.976860</td>\n      <td>40.756917</td>\n      <td>-73.975342</td>\n      <td>40.757473</td>\n      <td>1.656141</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.628164</td>\n      <td>0.014635</td>\n      <td>0.018170</td>\n      <td>0.015917</td>\n      <td>0.018661</td>\n      <td>1.284899</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.010000</td>\n      <td>-73.999999</td>\n      <td>40.700013</td>\n      <td>-73.999999</td>\n      <td>40.700020</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.500000</td>\n      <td>-73.988039</td>\n      <td>40.744947</td>\n      <td>-73.987125</td>\n      <td>40.745922</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.500000</td>\n      <td>-73.979691</td>\n      <td>40.758027</td>\n      <td>-73.978547</td>\n      <td>40.758559</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>10.100000</td>\n      <td>-73.967823</td>\n      <td>40.769580</td>\n      <td>-73.966435</td>\n      <td>40.770427</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>165.000000</td>\n      <td>-73.900062</td>\n      <td>40.799952</td>\n      <td>-73.900062</td>\n      <td>40.799999</td>\n      <td>6.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Question 1\n\nHere is the code to plot the partial dependence plot for `pickup_longitude`.  Run the following cell without changes.","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\nfeat_name = 'pickup_longitude'\npdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.683850Z","iopub.execute_input":"2023-02-28T18:19:47.684699Z","iopub.status.idle":"2023-02-28T18:19:47.771532Z","shell.execute_reply.started":"2023-02-28T18:19:47.684669Z","shell.execute_reply":"2023-02-28T18:19:47.769359Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/229239932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpdpbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeat_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pickup_longitude'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpdp_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdp_isolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdpbox'"],"ename":"ModuleNotFoundError","evalue":"No module named 'pdpbox'","output_type":"error"}]},{"cell_type":"markdown","source":"Why does the partial dependence plot have this U-shape?\n\nDoes your explanation suggest what shape to expect in the partial dependence plots for the other features?\n\nCreate all other partial plots in a for-loop below (copying the appropriate lines from the code above).","metadata":{}},{"cell_type":"code","source":"for feat_name in base_features:\n    pdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X,\n                               model_features=base_features, feature=feat_name)\n    pdp.pdp_plot(pdp_dist, feat_name)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.772174Z","iopub.status.idle":"2023-02-28T18:19:47.772521Z","shell.execute_reply.started":"2023-02-28T18:19:47.772329Z","shell.execute_reply":"2023-02-28T18:19:47.772347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do the shapes match your expectations for what shapes they would have? Can you explain the shape now that you've seen them? \n\nUncomment the following line to check your intuition.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_1.solution()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.774627Z","iopub.status.idle":"2023-02-28T18:19:47.775146Z","shell.execute_reply.started":"2023-02-28T18:19:47.774915Z","shell.execute_reply":"2023-02-28T18:19:47.774942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 2\n\nNow you will run a 2D partial dependence plot.  As a reminder, here is the code from the tutorial.  \n\n```\nfig, ax = plt.subplots(figsize=(8, 6))\nf_names = [('Goal Scored', 'Distance Covered (Kms)')]\nPartialDependenceDisplay.from_estimator(tree_model, val_X, f_names, ax=ax)\nplt.show()\n```\n\nCreate a 2D plot for the features `pickup_longitude` and `dropoff_longitude`.\n\nWhat do you expect it to look like?","metadata":{}},{"cell_type":"code","source":"# fig, ax = plt.subplots(figsize=(8, 6))\n\n# Add your code here\nfnames = ['pickup_longitude', 'dropoff_longitude']\nlongitudes_partial_plot  =  pdp.pdp_interact(model=first_model, dataset=val_X,\n                                            model_features=base_features, features=fnames)\npdp.pdp_interact_plot(pdp_interact_out=longitudes_partial_plot,\n                      feature_names=fnames, plot_type='contour')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.776968Z","iopub.status.idle":"2023-02-28T18:19:47.777488Z","shell.execute_reply.started":"2023-02-28T18:19:47.777227Z","shell.execute_reply":"2023-02-28T18:19:47.777252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment the line below to see the solution and explanation for how one might reason about the plot shape.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_2.solution()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.778894Z","iopub.status.idle":"2023-02-28T18:19:47.779281Z","shell.execute_reply.started":"2023-02-28T18:19:47.779093Z","shell.execute_reply":"2023-02-28T18:19:47.779112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 3\nConsider a ride starting at longitude -73.955 and ending at longitude -74. Using the graph from the last question, estimate how much money the rider would have saved if they'd started the ride at longitude -73.98 instead.","metadata":{}},{"cell_type":"code","source":"savings_from_shorter_trip = 15\n\n# Check your answer\nq_3.check()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.781001Z","iopub.status.idle":"2023-02-28T18:19:47.781396Z","shell.execute_reply.started":"2023-02-28T18:19:47.781204Z","shell.execute_reply":"2023-02-28T18:19:47.781223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For a solution or hint, uncomment the appropriate line below.","metadata":{}},{"cell_type":"code","source":"# q_3.hint()\n# q_3.solution()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.783351Z","iopub.status.idle":"2023-02-28T18:19:47.783858Z","shell.execute_reply.started":"2023-02-28T18:19:47.783656Z","shell.execute_reply":"2023-02-28T18:19:47.783683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 4\nIn the PDP's you've seen so far, location features have primarily served as a proxy to capture distance traveled. In the permutation importance lessons, you added the features `abs_lon_change` and `abs_lat_change` as a more direct measure of distance.\n\nCreate these features again here. You only need to fill in the top two lines.  Then run the following cell.  \n\n**After you run it, identify the most important difference between this partial dependence plot and the one you got without absolute value features. The code to generate the PDP without absolute value features is at the top of this code cell.**\n\n---","metadata":{}},{"cell_type":"code","source":"# This is the PDP for pickup_longitude without the absolute difference features. Included here to help compare it to the new PDP you create\nfeat_name = 'pickup_longitude'\npdp_dist_original = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n\npdp.pdp_plot(pdp_dist_original, feat_name)\nplt.show()\n\n\n\n# create new features\ndata['abs_lon_change'] = abs(data.dropoff_longitude - data.pickup_longitude)\ndata['abs_lat_change'] = abs(data.dropoff_latitude - data.pickup_latitude)\n\nfeatures_2  = ['pickup_longitude',\n               'pickup_latitude',\n               'dropoff_longitude',\n               'dropoff_latitude',\n               'abs_lat_change',\n               'abs_lon_change']\n\nX = data[features_2]\nnew_train_X, new_val_X, new_train_y, new_val_y = train_test_split(X, y, random_state=1)\nsecond_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(new_train_X, new_train_y)\n\nfeat_name = 'pickup_longitude'\npdp_dist = pdp.pdp_isolate(model=second_model, dataset=new_val_X, model_features=features_2, feature=feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()\n\n# Check your answer\nq_4.check()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.785213Z","iopub.status.idle":"2023-02-28T18:19:47.785604Z","shell.execute_reply.started":"2023-02-28T18:19:47.785432Z","shell.execute_reply":"2023-02-28T18:19:47.785455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment the line below to see a hint or the solution (including an explanation of the important differences between the plots).","metadata":{}},{"cell_type":"code","source":"# q_4.hint()\n# q_4.solution()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.787639Z","iopub.status.idle":"2023-02-28T18:19:47.788271Z","shell.execute_reply.started":"2023-02-28T18:19:47.787997Z","shell.execute_reply":"2023-02-28T18:19:47.788026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 5\nConsider a scenario where you have only 2 predictive features, which we will call `feat_A` and `feat_B`. Both features have minimum values of -1 and maximum values of 1.  The partial dependence plot for `feat_A` increases steeply over its whole range, whereas the partial dependence plot for feature B increases at a slower rate (less steeply) over its whole range.\n\nDoes this guarantee that `feat_A` will have a higher permutation importance than `feat_B`.  Why or why not?\n\nAfter you've thought about it, uncomment the line below for the solution.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_5.solution()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.790483Z","iopub.status.idle":"2023-02-28T18:19:47.792051Z","shell.execute_reply.started":"2023-02-28T18:19:47.791854Z","shell.execute_reply":"2023-02-28T18:19:47.791880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 6\nThe code cell below does the following:\n\n1. Creates two features, `X1` and `X2`, having random values in the range [-2, 2].\n2. Creates a target variable `y`, which is always 1.\n3. Trains a `RandomForestRegressor` model to predict `y` given `X1` and `X2`.\n4. Creates a PDP plot for `X1` and a scatter plot of `X1` vs. `y`.\n\nDo you have a prediction about what the PDP plot will look like? Run the cell to find out.\n\nModify the initialization of `y` so that our PDP plot has a positive slope in the range [-1,1], and a negative slope everywhere else. (Note: *you should only modify the creation of `y`, leaving `X1`, `X2`, and `my_model` unchanged.*)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom numpy.random import rand\n\nn_samples = 20000\n\n# Create array holding predictive feature\nX1 = 4 * rand(n_samples) - 2\nX2 = 4 * rand(n_samples) - 2\n# Create y. you should have X1 and X2 in the expression for y\ny = -2 * X1 * (X1<-1) + X1 - 2 * X1 * (X1>1) - X2\n\n# create dataframe because pdp_isolate expects a dataFrame as an argument\nmy_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\npredictors_df = my_df.drop(['y'], axis=1)\n\nmy_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n\npdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\n\n# visualize your results\npdp.pdp_plot(pdp_dist, 'X1')\nplt.show()\n\n# Check your answer\nq_6.check()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.793011Z","iopub.status.idle":"2023-02-28T18:19:47.793718Z","shell.execute_reply.started":"2023-02-28T18:19:47.793528Z","shell.execute_reply":"2023-02-28T18:19:47.793549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment the lines below for a hint or solution","metadata":{}},{"cell_type":"code","source":"# q_6.hint()\n# q_6.solution()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.794718Z","iopub.status.idle":"2023-02-28T18:19:47.795057Z","shell.execute_reply.started":"2023-02-28T18:19:47.794896Z","shell.execute_reply":"2023-02-28T18:19:47.794915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 7\nCreate a dataset with 2 features and a target, such that the pdp of the first feature is flat, but its permutation importance is high.  We will use a RandomForest for the model.\n\n*Note: You only need to supply the lines that create the variables X1, X2 and y. The code to build the model and calculate insights is provided*.","metadata":{}},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nn_samples = 20000\n\n# Create array holding predictive feature\nX1 = 4 * rand(n_samples) - 2\nX2 = 4 * rand(n_samples) - 2\n# Create y. you should have X1 and X2 in the expression for y\ny = X1 * X2\n\n\n# create dataframe because pdp_isolate expects a dataFrame as an argument\nmy_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\npredictors_df = my_df.drop(['y'], axis=1)\n\nmy_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n\n\npdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\npdp.pdp_plot(pdp_dist, 'X1')\nplt.show()\n\nperm = PermutationImportance(my_model).fit(predictors_df, my_df.y)\n\n# Check your answer\nq_7.check()\n\n# show the weights for the permutation importance you just calculated\neli5.show_weights(perm, feature_names = ['X1', 'X2'])","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.796163Z","iopub.status.idle":"2023-02-28T18:19:47.796511Z","shell.execute_reply.started":"2023-02-28T18:19:47.796321Z","shell.execute_reply":"2023-02-28T18:19:47.796339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uncomment the following lines for the hint or solution\n# q_7.hint()\n# q_7.solution()","metadata":{"execution":{"iopub.status.busy":"2023-02-28T18:19:47.797709Z","iopub.status.idle":"2023-02-28T18:19:47.798044Z","shell.execute_reply.started":"2023-02-28T18:19:47.797883Z","shell.execute_reply":"2023-02-28T18:19:47.797903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Keep Going\n\nPartial dependence plots can be really interesting. We have a [discussion thread](https://www.kaggle.com/learn-forum/65782) to talk about what real-world topics or questions you'd be curious to see addressed with partial dependence plots. \n\nNext, learn how **[SHAP values](https://www.kaggle.com/dansbecker/shap-values)** help you understand the logic for each individual prediction.\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/machine-learning-explainability/discussion) to chat with other learners.*","metadata":{}}]}